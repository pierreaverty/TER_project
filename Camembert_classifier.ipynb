{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff4b3fb",
   "metadata": {},
   "source": [
    "# Ensemble des import necessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0941e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertForSequenceClassification, CamembertTokenizer, AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c72cc",
   "metadata": {},
   "source": [
    "# Parsing du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e6592b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"Êtes-vous prêt à faire rendre des comptes à  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"Inapproprié [malade] pour vous ? Normal pour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"Les termes «Cabale» et «État profond» font ré...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"Le pire, c'est qu'ils adorent Satan et commet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"Symboles et logos utilisés par les pédophiles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"Les crises économique et terroriste de 2008 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"à la différence de la crise financière de 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"Dans l’instant, la photographie de la situati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"Ce recul relativement faible du revenu des mé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"Il ne faudrait pas que la crise du Covid soit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1475 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                           sentence\n",
       "0         radical  \"Êtes-vous prêt à faire rendre des comptes à  ...\n",
       "1         radical  \"Inapproprié [malade] pour vous ? Normal pour ...\n",
       "2         radical  \"Les termes «Cabale» et «État profond» font ré...\n",
       "3         radical  \"Le pire, c'est qu'ils adorent Satan et commet...\n",
       "4         radical  \"Symboles et logos utilisés par les pédophiles...\n",
       "...           ...                                                ...\n",
       "1470  non_radical  \"Les crises économique et terroriste de 2008 e...\n",
       "1471  non_radical  \"à la différence de la crise financière de 200...\n",
       "1472  non_radical  \"Dans l’instant, la photographie de la situati...\n",
       "1473  non_radical  \"Ce recul relativement faible du revenu des mé...\n",
       "1474  non_radical  \"Il ne faudrait pas que la crise du Covid soit...\n",
       "\n",
       "[1475 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parsing du fichier\n",
    "res = []\n",
    "\n",
    "with open(\"./corpus__fasttext.txt\",\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        label, sentence = line.split(\" \",1)   \n",
    "        res.append((label.replace(\"__label__\",\"\"), sentence))    \n",
    "        \n",
    "df = pd.DataFrame(res,columns=[\"label\",\"sentence\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23801062",
   "metadata": {},
   "source": [
    "# Infos sur les donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c6cb7f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre moyen de mots 45.\n",
      "Nombre max de mots 281.\n"
     ]
    }
   ],
   "source": [
    "#Petite infos\n",
    "print('Nombre moyen de mots {0:.0f}.'.format(np.mean(dataset['sentence'].apply(lambda x: len(x.split())))))\n",
    "print('Nombre max de mots {0:.0f}.'.format(np.mean(dataset['sentence'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b394b7c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de974e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            label                                           sentence\n",
      "0         radical  \"Vaccination puis puçage obligatoire comme pou...\n",
      "1         radical  \"Le site ultra-sioniste Dreuz.info, se charge ...\n",
      "2         radical  \"Rejoignez l'association si vous voulez partic...\n",
      "3         radical  \"L’ouvrier noir, malgré les efforts de Trump, ...\n",
      "4         radical  \"Ceux q’u’il faut euthanasier, c’est cette pou...\n",
      "...           ...                                                ...\n",
      "1175  non_radical  \"Ce narcissisme, si bien décrit par l'historie...\n",
      "1176  non_radical  \"Le modèle dominant fondé sur l’énergie bon ma...\n",
      "1177  non_radical  \"Attention, loin de moi l’idée de demander à q...\n",
      "1178  non_radical  \"\"\"VOTRE VOIX ET VOTRE VOTE SONT CE QUI COMPTE...\n",
      "1179  non_radical  \"Selon Missoum Chaoui (aumônier pénitencier), ...\n",
      "\n",
      "[1180 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"L’islam, moderne , çan’existe pas ! Il suffit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"Passé 20 %, le musulman a déjà proclamé la ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"En pratique, c’est le bourgeois frontiste de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"D’après les commentaires des articles de Ripo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>radical</td>\n",
       "      <td>\"L'empire de la République, nous le ressentons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"L’originalité technocratique française est de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"Croit-on sérieusement qu’un peuple qu’on main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"L'émission Quotidien offre un « temps de cerv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"Je me suis contenté comme bon nombre d’interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>non_radical</td>\n",
       "      <td>\"Cette réalité de relâchements massifs de gaz ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                           sentence\n",
       "0        radical  \"L’islam, moderne , çan’existe pas ! Il suffit...\n",
       "1        radical  \"Passé 20 %, le musulman a déjà proclamé la ch...\n",
       "2        radical  \"En pratique, c’est le bourgeois frontiste de ...\n",
       "3        radical  \"D’après les commentaires des articles de Ripo...\n",
       "4        radical  \"L'empire de la République, nous le ressentons...\n",
       "..           ...                                                ...\n",
       "290  non_radical  \"L’originalité technocratique française est de...\n",
       "291  non_radical  \"Croit-on sérieusement qu’un peuple qu’on main...\n",
       "292  non_radical  \"L'émission Quotidien offre un « temps de cerv...\n",
       "293  non_radical  \"Je me suis contenté comme bon nombre d’interv...\n",
       "294  non_radical  \"Cette réalité de relâchements massifs de gaz ...\n",
       "\n",
       "[295 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separation des dataset pour les refusionner plus tard\n",
    "df_radical = df.groupby('label').get_group('radical')\n",
    "df_non_radical = df.groupby('label').get_group('non_radical')\n",
    "\n",
    "#Permet d'avoir les meme proportion pour le df_training et le df_validation\n",
    "part1_rad, part2_rad = train_test_split(df_radical, test_size=0.2, random_state=13)\n",
    "part1_non_rad, part2_non_rad = train_test_split(df_non_radical, test_size=0.2, random_state=13)\n",
    "\n",
    "df_training =  pd.merge(part1_rad, part1_non_rad, how='outer')\n",
    "df_validation =  pd.merge(part2_rad, part2_non_rad, how='outer')\n",
    "\n",
    "print(df_training)\n",
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b10e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On convertie radical en 1 et pas radical en 0\n",
    "training_sentence = df_training['sentence'].values.tolist()\n",
    "training_label = [1 if x=='radical' else 0 for x in df_training['label']]\n",
    "\n",
    "\n",
    "validation_sentence = df_validation['sentence'].values.tolist()\n",
    "validation_label = [1 if x=='radical' else 0 for x in df_validation['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "406a03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement du tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)\n",
    "\n",
    "#On encode les sentences pour pouvoir les passer a Camenbert\n",
    "train_sentence_enco = tokenizer.batch_encode_plus(training_sentence,add_special_tokens=True, max_length=90,padding=True,truncation=True,return_attention_mask = True,return_tensors = 'pt')\n",
    "val_sentence_enco = tokenizer.batch_encode_plus(validation_sentence,add_special_tokens=True, max_length=90,padding=True,truncation=True,return_attention_mask = True,return_tensors = 'pt')\n",
    "\n",
    "\n",
    "# On transforme en tenseur les labels\n",
    "train_label_tensor = torch.tensor(training_label)\n",
    "val_label_tensor = torch.tensor(validation_label)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(train_sentence_enco['input_ids'],train_sentence_enco['attention_mask'],train_label_tensor)\n",
    "\n",
    "validation_dataset = TensorDataset(val_sentence_enco['input_ids'],val_sentence_enco['attention_mask'],val_label_tensor)\n",
    "\n",
    "\n",
    "#Taille des batchs qui vont être utilisés pour l'entraînement.\n",
    "batch_size = 16\n",
    " \n",
    "# Le dataloader un objet iterable\n",
    "# RandomSampler permet d'iterer le jeu d'entrainement de façon aleatoire\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size)\n",
    " \n",
    "val_dataloader = DataLoader(\n",
    "            validation_dataset,\n",
    "            sampler = SequentialSampler(validation_dataset),\n",
    "            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf278e95",
   "metadata": {},
   "source": [
    "# Mise en place du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4813b3de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# CamembertForSequenceClassification = Camebert + couche de classification\n",
    "model = CamembertForSequenceClassification.from_pretrained(\n",
    "    'camembert-base',\n",
    "    num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6089be63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#L'optimiser ajuste les poids du modèle lors de l'apprentissage\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-4 , # Learning Rate faible petit jeu de donnees\n",
    "                  eps = 1e-8 # Epsilon\n",
    "                 )\n",
    "epochs = 2 #nb de fois que le modèle va parcourir l'ensemble de données lors de l'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f8323",
   "metadata": {},
   "source": [
    "# Entrainement du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca75ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 2\n",
      "Runing...\n",
      "\tloss moyen : 0.8421237587928772 etape 5  sur 74.\n",
      "\tloss moyen : 0.748769211769104 etape 10  sur 74.\n",
      "\tloss moyen : 0.7255592743555704 etape 15  sur 74.\n",
      "\tloss moyen : 0.7090709865093231 etape 20  sur 74.\n",
      "\tloss moyen : 0.7001602005958557 etape 25  sur 74.\n",
      "\tloss moyen : 0.6830982804298401 etape 30  sur 74.\n",
      "\tloss moyen : 0.6782545345170158 etape 35  sur 74.\n",
      "\tloss moyen : 0.6721162647008896 etape 40  sur 74.\n",
      "\tloss moyen : 0.6653674536281162 etape 45  sur 74.\n",
      "\tloss moyen : 0.6695031797885895 etape 50  sur 74.\n",
      "\tloss moyen : 0.6688793204047463 etape 55  sur 74.\n",
      "\tloss moyen : 0.6692936152219773 etape 60  sur 74.\n",
      "\tloss moyen : 0.6602517247200013 etape 65  sur 74.\n",
      "\tloss moyen : 0.6520907163619996 etape 70  sur 74.\n",
      "\tloss moyen : 0.6515534454829073 etape 73  sur 74.\n",
      "\tMoyenne de la loss: 0.64\n",
      "\n",
      "Epoch 2 / 2\n",
      "Runing...\n",
      "\tloss moyen : 0.6018055081367493 etape 5  sur 74.\n",
      "\tloss moyen : 0.5256553888320923 etape 10  sur 74.\n",
      "\tloss moyen : 0.520179812113444 etape 15  sur 74.\n",
      "\tloss moyen : 0.528798571228981 etape 20  sur 74.\n",
      "\tloss moyen : 0.5211324679851532 etape 25  sur 74.\n",
      "\tloss moyen : 0.510164675116539 etape 30  sur 74.\n",
      "\tloss moyen : 0.4919642465455191 etape 35  sur 74.\n",
      "\tloss moyen : 0.49600759893655777 etape 40  sur 74.\n",
      "\tloss moyen : 0.48991829223102995 etape 45  sur 74.\n",
      "\tloss moyen : 0.49935593247413634 etape 50  sur 74.\n",
      "\tloss moyen : 0.5145905754782937 etape 55  sur 74.\n",
      "\tloss moyen : 0.5136609102288882 etape 60  sur 74.\n",
      "\tloss moyen : 0.5086068006662222 etape 65  sur 74.\n",
      "\tloss moyen : 0.5183278381824493 etape 70  sur 74.\n",
      "\tloss moyen : 0.5182487780917181 etape 73  sur 74.\n",
      "\tMoyenne de la loss: 0.51\n",
      "Model sauvegarder!\n"
     ]
    }
   ],
   "source": [
    "# Def de ou vont etre stocker les tenseurs\n",
    "device = torch.device(\"cpu\")\n",
    " \n",
    "def train(model,train_dataloader,epochs) :\n",
    "    # Boucle d'entrainement\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1} / {epochs}\")\n",
    "        print(\"Runing...\")\n",
    "\n",
    "        # On reinitialise la loss pour cette epoque\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # Modele en mode train\n",
    "        model.train()\n",
    "\n",
    "        # Pour chaque batch\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Recuperation des donnees du batch\n",
    "            input_id = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            label = batch[2].to(device)\n",
    "\n",
    "            # On met le gradient a 0\n",
    "            model.zero_grad()        \n",
    "\n",
    "            # On passe la donnee au model et on recupere la loss\n",
    "            md = model(input_id, token_type_ids=None,attention_mask=attention_mask,labels=label)\n",
    "            loss = md.loss\n",
    "\n",
    "            # .item() donne la valeur numerique de la loss\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            if (step % 5 == 0 and not step == 0) or step == len(train_dataloader)-1:\n",
    "                print(f\"\\tloss moyen : {total_train_loss/step} etape {step}  sur {len(train_dataloader)}.\")\n",
    "\n",
    "            # Backprop\n",
    "            loss.backward()\n",
    "\n",
    "            # On actualise les parametrer grace a l'optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"\\tMoyenne de la loss: {0:.2f}\".format(total_train_loss / len(train_dataloader) ))  \n",
    "\n",
    "train(model,train_dataloader,epochs)\n",
    "print(\"Model sauvegarder!\")\n",
    "torch.save(model.state_dict(), \"save.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5884e48a",
   "metadata": {},
   "source": [
    "# Evaluation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ba3c7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6542372881355932\n"
     ]
    }
   ],
   "source": [
    "def evaluation(dataloader,model) :\n",
    "    # Mettre le modèle en mode d'évaluation\n",
    "    model.eval()\n",
    "\n",
    "    # Variables pour stocker les prédictions et les vraies étiquettes\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    # Boucle pour prédire chaque batch de données de test\n",
    "    for batch in dataloader:\n",
    "\n",
    "        # Récupérer les données du batch\n",
    "        input_id = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        label = batch[2].to(device)\n",
    "\n",
    "        # Désactiver l'optimisation pour économiser de la mémoire\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Passer les données au modèle pour obtenir la prédiction et les logits\n",
    "            md = model(input_id, \n",
    "                                 token_type_ids=None, \n",
    "                                 attention_mask=attention_mask, \n",
    "                                 labels=label)\n",
    "            logits = md.logits\n",
    "\n",
    "        # Convertir les logits en prédictions de classe\n",
    "        batch_predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Ajouter les prédictions et les vraies étiquettes à la liste correspondante\n",
    "        predictions.extend(batch_predictions)\n",
    "        true_labels.extend(label)\n",
    "\n",
    "    #Calculer la précision du modèle sur les données de test\n",
    "    accuracy = metrics.accuracy_score(true_labels, predictions)\n",
    "    print(\"Precision:\", accuracy)\n",
    "    \n",
    "evaluation(val_dataloader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "636bc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charger un model\n",
    "model_path = \"save.pt\"\n",
    "model_dict = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83954b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
